{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your WaPOR API Token: f931d000c500d538478b92992be10702c08e8656b6b54d43d8eecfad9ee8edeee4b34903360c03ac\n"
     ]
    }
   ],
   "source": [
    "#import WAPORWA modules_______________________________________________________________________________________\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\h.jayasekara\\Downloads\\modules\\modules') #change to modules path\n",
    "# ____________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "import glob\n",
    "import WaPOR\n",
    "import WA\n",
    "from WA.pickle_basin import pickle_in,pickle_out  \n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import osr\n",
    "from WaPOR import GIS_functions as gis\n",
    "import calendar\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterstats import zonal_stats\n",
    "import json\n",
    "\n",
    "\n",
    "# f931d000c500d538478b92992be10702c08e8656b6b54d43d8eecfad9ee8edeee4b34903360c03ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data from WAPOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WaPOR.API.version=2\n",
    "catalog=WaPOR.API.getCatalog()\n",
    "\n",
    "INPUT_FOLDER=r'C:\\Users\\h.jayasekara\\Desktop\\WaporData' #change to input path\n",
    "\n",
    "#%% DEFINE Basin extent\n",
    "### OPTION 1: Define minimum and maximum longitude (x) and latitude (y)\n",
    "# xmin,ymin,xmax,ymax=[34.4,29.4,37.0,33.7]\n",
    "\n",
    "### OPTION 2: Read from shapefile\n",
    "BASIN_SHP = r'C:\\Users\\h.jayasekara\\Downloads\\Sri Lanka SHP\\Provinces\\Provinces_SL.shp' #path to Basin shapefile\n",
    "import shapefile\n",
    "shape=shapefile.Reader(BASIN_SHP)\n",
    "xmin,ymin,xmax,ymax=shape.bbox\n",
    "\n",
    "start_date='2022-03-01'\n",
    "end_date='2022-12-31'\n",
    "\n",
    "# WaPOR.PCP_daily(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.25,ymax+0.25],\n",
    "#                   lonlim=[xmin-0.25,xmax+0.25])\n",
    "\n",
    "# WaPOR.PCP_monthly(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.25,ymax+0.25],\n",
    "#                   lonlim=[xmin-0.25,xmax+0.25])\n",
    "\n",
    "# WaPOR.RET_monthly(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.5,ymax+0.5],\n",
    "#                   lonlim=[xmin-0.5,xmax+0.5])\n",
    "\n",
    "# WaPOR.LCC_yearly(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin,ymax],\n",
    "#                   lonlim=[xmin,xmax],level=2)\n",
    "\n",
    "# WaPOR.I_dekadal(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin,ymax],\n",
    "#                   lonlim=[xmin,xmax],level=2)\n",
    "\n",
    "# WaPOR.AET_monthly(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.5,ymax+0.5],\n",
    "#                   lonlim=[xmin-0.5,xmax+0.5],level=2)\n",
    "\n",
    "WaPOR.NPP_monthly(INPUT_FOLDER,Startdate=start_date,\n",
    "                  Enddate=end_date,latlim=[ymin-0.5,ymax+0.5],\n",
    "                  lonlim=[xmin-0.5,xmax+0.5],level=2)\n",
    "\n",
    "# WaPOR.E_dekadal(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.5,ymax+0.5],\n",
    "#                   lonlim=[xmin-0.5,xmax+0.5],level=2)\n",
    "\n",
    "# WaPOR.T_dekadal(INPUT_FOLDER,Startdate=start_date,\n",
    "#                   Enddate=end_date,latlim=[ymin-0.5,ymax+0.5],\n",
    "#                   lonlim=[xmin-0.5,xmax+0.5],level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Biomass ( using NPP data ) or ET for the Maha season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WaPOR catalog...\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# user inputs ________________________________________________________________________________________________\n",
    "\n",
    "Monthly_product_folder=r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\L2_NPP_M\" #insert file path\n",
    "ds_code='L2_NPP_M'    #ds code for file naming should insetr refering WaPOR docs\n",
    "shapefile = r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\Sri_lanka\\final1.shp\"     #path_to_shapefile.shp\n",
    "start_date='2015-01-01'\n",
    "end_date='2022-12-31'\n",
    "season = \"Maha\"  # select the season  -->  \"Maha\"  \"Yala\"\n",
    "# ____________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "product_name = ds_code.split(\"_\")\n",
    "naming_product = product_name[1]\n",
    "\n",
    "path_split = os.path.split(Monthly_product_folder)\n",
    "ds_code_f = path_split[1]\n",
    "\n",
    "#output folder name\n",
    "# output_folder=Monthly_product_folder.replace(ds_code_f,'Maha_{}'.format(naming_product)) \n",
    "\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "    \n",
    "\n",
    "if (naming_product == \"NPP\"):\n",
    "    \n",
    "    Biomass_out = Monthly_product_folder.replace(ds_code_f,'Maha_{}_to_Biomass'.format(naming_product)) \n",
    "    if not os.path.exists(Biomass_out):\n",
    "        os.makedirs(Biomass_out)\n",
    "        \n",
    "    res_product = \"biomass\"\n",
    "    \n",
    "elif (naming_product == \"AETI\"):\n",
    "    \n",
    "    ET_out = Monthly_product_folder.replace(ds_code_f,'Maha_{}'.format(naming_product)) \n",
    "    if not os.path.exists(ET_out):\n",
    "        os.makedirs(ET_out)\n",
    "        \n",
    "    res_product = \"AETI\"\n",
    "        \n",
    "else:\n",
    "    print(\"error in ds_code you entered\")\n",
    "    sys.exit()\n",
    "\n",
    "# ____________________________________________________________________________________________________________\n",
    "    \n",
    "    \n",
    "input_fhs=glob.glob(os.path.join(Monthly_product_folder,'*.tif'))\n",
    "input_fhs\n",
    "\n",
    "#Get year to array\n",
    "year_dates=pd.date_range(start_date,end_date,freq='Y')\n",
    "\n",
    "\n",
    "\n",
    "print (\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array for year 2023 not found in sumArrays_Jan_Mar_\n"
     ]
    }
   ],
   "source": [
    "# # create the sum image _____________________________________________________________________________________\n",
    "#Get df avail \n",
    "WaPOR.API.version=2\n",
    "df_avail=WaPOR.API.getAvailData(ds_code,time_range='{0},{1}'.format(start_date,end_date))\n",
    "\n",
    "\n",
    "driver, NDV, xsize, ysize, GeoT, Projection = gis.GetGeoInfo(input_fhs[0])\n",
    "sumArrays_Jan_Mar_ = {}\n",
    "sumArrays_Nov_Dec_ = {}\n",
    "\n",
    "# for creating sumArray for Jan to Mar\n",
    "\n",
    "\n",
    "for date in year_dates:   \n",
    "    year_fhs=[]\n",
    "    \n",
    "    for fh in input_fhs:\n",
    "        raster_id=os.path.split(fh)[-1].split('.tif')[0][-7:]\n",
    "        year=int(raster_id[0:4])\n",
    "        month=int(raster_id[5:7])\n",
    "        if (year == date.year) &  (month == 1 or month == 2 or month == 3):\n",
    "            year_fhs.append(fh)\n",
    "            \n",
    "    SumArray=np.zeros((ysize,xsize),dtype=np.float32)\n",
    "    for f in year_fhs:\n",
    "        Array=gis.OpenAsArray(f,nan_values=True)\n",
    "        SumArray+=Array\n",
    "        \n",
    "    sumArrays_Jan_Mar_[date.year] = SumArray\n",
    "     \n",
    "\n",
    "# for creating sumArray for Nov to Dec  \n",
    "\n",
    "for date in year_dates:\n",
    "    year_fhs=[]\n",
    "    \n",
    "    for fh in input_fhs:\n",
    "        raster_id=os.path.split(fh)[-1].split('.tif')[0][-7:]\n",
    "        year=int(raster_id[0:4])\n",
    "        month=int(raster_id[5:7])\n",
    "        if (year == date.year) &  (month == 11 or month == 12):\n",
    "            year_fhs.append(fh)\n",
    "            \n",
    "    SumArray=np.zeros((ysize,xsize),dtype=np.float32)\n",
    "    for f in year_fhs:\n",
    "        Array=gis.OpenAsArray(f,nan_values=True)\n",
    "        SumArray+=Array\n",
    "        \n",
    "    sumArrays_Nov_Dec_[date.year] = SumArray\n",
    "    \n",
    "    \n",
    "# create the final array & save it ___________________________________________________________________________      \n",
    "\n",
    "    \n",
    "output_folder_clip=Monthly_product_folder.replace(ds_code_f,'{}_{}_Clipped'.format(season,res_product))\n",
    "if not os.path.exists(output_folder_clip):\n",
    "    os.makedirs(output_folder_clip)\n",
    "\n",
    "# read shp file\n",
    "gdf = gpd.read_file(shapefile)  \n",
    "    \n",
    "for date in year_dates:\n",
    "\n",
    "    if date.year not in sumArrays_Nov_Dec_:\n",
    "        print(\"Array for year {} not found in sumArrays_Nov_Dec_\".format(date.year))\n",
    "        continue\n",
    "        \n",
    "    if (date.year+1) not in sumArrays_Jan_Mar_:\n",
    "        print(\"Array for year {} not found in sumArrays_Jan_Mar_\".format(date.year+1))\n",
    "        continue\n",
    "        \n",
    "    Maha_sumArray = sumArrays_Jan_Mar_[date.year+1] + sumArrays_Nov_Dec_[date.year]\n",
    "    \n",
    "\n",
    "    Maha_sumArray_c =  Maha_sumArray\n",
    "    \n",
    "    \n",
    "    if (naming_product == \"NPP\"): \n",
    "        \n",
    "        biomass = Maha_sumArray_c * 88.888 / 2.55\n",
    "\n",
    "        # Save the biomass as a GeoTIFF file\n",
    "        out_fh = os.path.join(Biomass_out, 'WaPOR_{}_Biomass_{}.tif'.format(season,date.year))  \n",
    "        gis.CreateGeoTiff(out_fh, biomass, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "    \n",
    "    elif (naming_product == \"AETI\"):\n",
    "        \n",
    "        # Save the product as a GeoTIFF file\n",
    "        out_fh = os.path.join(ET_out, 'WaPOR_{}_ET_{}.tif'.format(season,date.year))  \n",
    "        gis.CreateGeoTiff(out_fh, Maha_sumArray_c, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "        \n",
    "#     with rasterio.open(out_fh) as src:\n",
    "#         out_image, out_transform = rasterio.mask.mask(src, gdf.geometry, crop=True)\n",
    "#         out_meta = src.meta.copy()\n",
    "\n",
    "#     out_meta.update({\"driver\": \"GTiff\",\n",
    "#                      \"height\": out_image.shape[1],\n",
    "#                      \"width\": out_image.shape[2],\n",
    "#                      \"transform\": out_transform})\n",
    "\n",
    "#     with rasterio.open(os.path.join(ET_out, 'WaPOR_ET_{}_clipped.tif'.format(date.year)), \"w\", **out_meta) as dest:\n",
    "#         dest.write(out_image)\n",
    "        \n",
    "    #clipping the product created ____________________________________________________________________________ \n",
    "    \n",
    "    with rasterio.open(out_fh) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, gdf.geometry, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "\n",
    "    with rasterio.open(os.path.join(output_folder_clip, 'WaPOR_{}_{}.tif'.format(res_product,date.year)), \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "\n",
    "    \n",
    "# ____________________________________________________________________________________________________________\n",
    "# if it is for a year summation\n",
    "# for date in year_dates:\n",
    "        \n",
    "#     year_fhs=[]\n",
    "# #     SumArray = np.zeros((ysize, xsize), dtype=np.float32)\n",
    "#     for fh in input_fhs:\n",
    "#         raster_id=os.path.split(fh)[-1].split('.tif')[0][-7:]\n",
    "#         year=int(raster_id[0:4])\n",
    "#         month=int(raster_id[5:7])\n",
    "#         if (year == date.year):\n",
    "#             year_fhs.append(fh)\n",
    "         \n",
    "#     SumArray=np.zeros((ysize,xsize),dtype=np.float32)\n",
    "#     for f in year_fhs:\n",
    "#         Array=gis.OpenAsArray(f,nan_values=True)\n",
    "#         SumArray+=Array\n",
    "        \n",
    "    \n",
    "#     SumArray = correction_factor * SumArray\n",
    "\n",
    "#     # Save the result as a GeoTIFF file\n",
    "#     out_fh = os.path.join(output_folder, 'WaPOR_{}_{}.tif'.format(naming_product,date.year))  \n",
    "#     gis.CreateGeoTiff(out_fh, SumArray, driver, NDV, xsize, ysize, GeoT, Projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculatiting zonal statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster for year 2022 not found in the dataset\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import fiona\n",
    "#  User inputs _______________________________________________________________________________________________\n",
    "\n",
    "res_product = \"water_productivity\" # select the product  -->  \"AETI\"  \"Biomass\" \"water_productivity\"\n",
    "season = \"Maha\"  # select the season  -->  \"Maha\"  \"Yala\"\n",
    "# ____________________________________________________________________________________________________________\n",
    "\n",
    "if (res_product == \"water_productivity\"):\n",
    "    req_folder = \"Water_productivity\"\n",
    "    req_file = \"Water_productivity\"\n",
    "    res_file = \"Water_productivity\"\n",
    "\n",
    "    \n",
    "if (res_product == \"AETI\"):\n",
    "    req_folder = \"Maha_AETI_Clipped\"\n",
    "    req_file = \"WaPOR_AETI\"\n",
    "    res_file = \"AETI\"\n",
    "\n",
    "    \n",
    "if (res_product == \"Biomass\"):\n",
    "    req_folder = \"Maha_biomass_Clipped\"\n",
    "    req_file = \"WaPOR_biomass\"\n",
    "    res_file = \"Biomass\"\n",
    "\n",
    "\n",
    "polygon =  r\"C:\\Users\\h.jayasekara\\Desktop\\admin\\lka_admbnda_adm1_slsd_20200305.shp\"\n",
    "# polygon =  r\"C:\\Users\\h.jayasekara\\Desktop\\admin\\lka_admbnda_adm2_slsd_20200305.shp\"\n",
    "# polygon =  r\"C:\\Users\\h.jayasekara\\Desktop\\admin\\lka_admbnda_adm3_slsd_20200305.shp\"\n",
    "# polygon =  r\"C:\\Users\\h.jayasekara\\Desktop\\admin\\lka_admbnda_adm4_slsd_20200305.shp\"\n",
    "\n",
    "polygon_split = os.path.split(polygon)[-1].split(\".shp\")\n",
    "file_name = polygon_split[0]\n",
    "file_split = file_name.split(\"_\")\n",
    "admin_level = file_split[2]\n",
    "\n",
    "\n",
    "if (admin_level == \"adm1\"):\n",
    "    OID = 'ADM1_PCODE'\n",
    "\n",
    "elif (admin_level == \"adm2\"):\n",
    "    OID = 'ADM2_PCODE'\n",
    "    \n",
    "\n",
    "elif (admin_level == \"adm3\"):\n",
    "    OID = 'ADM3_PCODE'\n",
    "    \n",
    "elif (admin_level == \"adm4\"):\n",
    "    OID = 'ADM4_PCODE'\n",
    "    \n",
    "else:\n",
    "    print(\"It seems the file name is not in the format used in this code\")\n",
    "    sys.exit()\n",
    "       \n",
    "gdf = gpd.read_file(polygon)\n",
    "\n",
    "zonal_statistics_province={}\n",
    "zonal_statistics_district={}\n",
    "zonal_statistics_DSD={}\n",
    "zonal_statistics_GND={}\n",
    "\n",
    "if not os.path.isdir(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\JSON_1\"):\n",
    "    os.makedirs(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\JSON_1\")\n",
    "\n",
    "for date in year_dates:\n",
    "\n",
    "    raster_1 = r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\{}\\{}_{}.tif\".format(req_folder,req_file,date.year)\n",
    "    if not os.path.isfile(raster_1):\n",
    "        print(\"raster for year {} not found in the dataset\".format(date.year))\n",
    "        continue\n",
    "        \n",
    "    raster_r = rasterio.open(raster_1)\n",
    "    array = raster_r.read(1)\n",
    "    affine = raster_r.transform\n",
    "\n",
    "    stat = zonal_stats(gdf, array ,affine = affine, stats= 'mean', nodata=-9999.0, geojson_out=True )\n",
    "    #  must be one of  ['count', 'min', 'max', 'mean', 'sum', 'std', 'median', 'majority', 'minority', 'unique', 'range', 'nodata', 'nan']\n",
    "    # the last nodata=-9999.0 is for exclude nodata values\n",
    "    \n",
    "    \n",
    "    # input id into zonal stat array\n",
    "#     stat_id = [{**s, 'id': row[1][OID]} for s, row in zip(stat, gdf.iterrows())]\n",
    "\n",
    "    \n",
    "    if (admin_level == \"adm1\"):\n",
    "        zonal_statistics_province[date.year] = stat\n",
    "        json_zonal_stat = json.dumps(zonal_statistics_province)\n",
    "\n",
    "\n",
    "    elif (admin_level == \"adm2\"):\n",
    "        zonal_statistics_district[date.year] = stat\n",
    "        json_zonal_stat = json.dumps(zonal_statistics_district)\n",
    "      \n",
    "\n",
    "    elif (admin_level == \"adm3\"):\n",
    "        zonal_statistics_DSD[date.year] = stat\n",
    "        json_zonal_stat = json.dumps(zonal_statistics_DSD)\n",
    "\n",
    "        \n",
    "        \n",
    "    elif (admin_level == \"adm4\"):\n",
    "        zonal_statistics_GND[date.year] = stat\n",
    "        json_zonal_stat = json.dumps(zonal_statistics_GND)        \n",
    "\n",
    "\n",
    "    jsonFile = open(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\JSON_1\\{}_{}_{}.geojson\".format(res_file,admin_level,date.year), \"w\")\n",
    "    jsonFile.write(json_zonal_stat)\n",
    "    jsonFile.close()\n",
    "# print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.isdir(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\csv\"):\n",
    "    os.makedirs(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\csv\")\n",
    "\n",
    "directory_path = r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\JSON\"\n",
    "files = os.listdir(directory_path)\n",
    "i=0\n",
    "\n",
    "while i<len(files):\n",
    "    \n",
    "    file_path = r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\JSON\\{}\".format(files[i])\n",
    "    file_split = os.path.split(file_path)[-1].split(\".json\")\n",
    "    file_name = file_split[0]\n",
    "    file_split = file_name.split(\"_\")\n",
    "    admin_level = file_split[-1]\n",
    "\n",
    "    file = open(file_path)\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    csv_file = r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\csv\\{}.csv\".format(file_name)\n",
    "    for year, values in data.items():\n",
    "        # Create a dataframe for the year's data\n",
    "        year_df = pd.DataFrame(values)\n",
    "        # Set the index of the year's dataframe to the \"id\" column\n",
    "        year_df.set_index(\"id\", inplace=True)\n",
    "        # Rename the \"mean\" column to the year\n",
    "        year_df.rename(columns={\"mean\": \"mean_{}\".format(year)}, inplace=True)\n",
    "#         year_df.rename(columns={\"id\":admin_level }, inplace=True)\n",
    "        # Append the year's dataframe to the main dataframe\n",
    "        df = pd.concat([df, year_df], axis=1)           \n",
    "\n",
    "\n",
    "    # save the dataframe to a CSV file\n",
    "    df.to_csv(csv_file, index=True)          \n",
    "\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Productivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for year 2022\n"
     ]
    }
   ],
   "source": [
    "Water_Productivity = Monthly_product_folder.replace(ds_code_f,'Water_productivity') \n",
    "if not os.path.exists(Water_Productivity):\n",
    "    os.makedirs(Water_Productivity)\n",
    "    \n",
    "for date in year_dates:    \n",
    "    try:\n",
    "        src1 = rasterio.open(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\Maha_Biomass_Clipped\\WaPOR_Biomass_{}.tif\".format(date.year))\n",
    "        src2 = rasterio.open(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\Maha_AETI_Clipped\\WaPOR_AETI_{}.tif\".format(date.year))\n",
    "\n",
    "        data1 = src1.read(1)\n",
    "        data2 = src2.read(1)\n",
    "\n",
    "        mask = data2 == 0\n",
    "        \n",
    "        result = np.zeros_like(data1, dtype=np.float32)\n",
    "        result[~mask] = np.divide(data1[~mask], data2[~mask])\n",
    "\n",
    "        nodata1 = src1.nodata\n",
    "        nodata2 = src2.nodata\n",
    "\n",
    "        if nodata1 is not None and nodata2 is not None:\n",
    "            nodata_mask = (data1 == nodata1) | (data2 == nodata2)\n",
    "            result[nodata_mask] = nodata1\n",
    "\n",
    "        meta = src1.meta\n",
    "        meta.update(dtype=result.dtype, count=1)\n",
    "\n",
    "        with rasterio.open(r\"C:\\Users\\h.jayasekara\\Desktop\\WaporData\\Water_productivity\\Water_productivity_{}.tif\".format(date.year), 'w', **meta) as dst:\n",
    "            dst.write(result, 1)\n",
    "            \n",
    "    except rasterio.RasterioIOError:\n",
    "        print(\"File not found for year {}\".format(date.year))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
